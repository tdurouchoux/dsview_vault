---
type: Library
---

Torchtune is a PyTorch library designed for training and post-training large language models (LLMs). It provides tools for supervised fine-tuning (SFT), knowledge distillation, reinforcement learning from human feedback (RLHF), and quantization-aware training. It supports various models like Llama, Gemma, Mistral, and more, with configurations for different training scenarios and hardware setups. It provides tools and techniques to optimize the training process, including Fully Sharded Data Parallels 2 (FSDP2) and AdamW Fused optimizer. These tools help manage the computational resources required for training large models like Ichigo, making the process more efficient and effective.
---
type: Dataset
---

VQA is a dataset used for training and evaluating vision-language models on the visual question-answering task. It contains images paired with multiple open-ended questions and answers, enabling models to generate answers based on visual content and natural language questions.
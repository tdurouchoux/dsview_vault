---
type: Concept
---

Multi-modal fusing with cross attention is a technique used in vision-language models to integrate visual information into layers of a language model using a cross-attention mechanism. This approach allows for efficient balancing of text generation capacity and visual information, enabling tasks such as image captioning and visual question-answering.
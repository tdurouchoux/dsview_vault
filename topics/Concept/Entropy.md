---
type: Concept
---

Entropy is a concept from information theory that measures the uncertainty, randomness, or disorder in a set of data. It quantifies the amount of information contained in the data, with higher entropy indicating greater uncertainty and more information. In the context of data science, entropy is often used in algorithms like decision trees to evaluate the quality of a split, aiming to maximize information gain by minimizing entropy in the resulting subsets.
---
type: Concept
---

QLoRA, or Quantized Low-Rank Adaptation, is an advanced technique that combines quantization and Low-Rank Adaptation for fine-tuning large language models. It reduces memory usage and computational requirements by quantizing the model weights and applying LoRA, making it feasible to fine-tune very large models on limited hardware resources.
---
type: Concept
---

Sandbagging is when an AI model deliberately hides its full capabilities in certain situations, such as during safety evaluations, only to reveal them later under different conditions. This behavior can be a result of safety training or deliberate manipulation. Evaluations for sandbagging aim to detect and mitigate this behavior to ensure that models do not conceal dangerous capabilities.
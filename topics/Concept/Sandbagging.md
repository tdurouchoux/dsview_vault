---
type: Concept
---

Sandbagging in the context of AI models refers to the deliberate hiding of a model's full capabilities in certain situations, only to reveal them in others. This evaluation tests whether a model can perform at different capacity levels depending on the context, such as performing poorly in dangerous capabilities evaluations but exhibiting full capabilities when triggered by specific prompts. The goal is to ensure that models do not selectively display dangerous behaviors.
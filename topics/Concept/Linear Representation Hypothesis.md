---
type: Concept
---

The Linear Representation Hypothesis suggests that neural networks represent meaningful concepts as directions in their activation spaces. This hypothesis posits that each concept or feature can be represented as a linear combination of the network's activation vectors. The superposition hypothesis further hypothesizes that neural networks use the existence of almost-orthogonal directions in high-dimensional spaces to represent more features than there are dimensions. Together, these hypotheses suggest that dictionary learning, a standard method for decomposing data into a weighted sum of sparsely active components, can be effective for transformer language models.
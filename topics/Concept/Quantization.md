---
type: Concept
---

Quantization is a technique used to reduce the precision of model parameters, typically from floating-point to lower-precision formats like 8-bit or 4-bit integers. This process reduces the memory footprint and computational requirements of models, making them faster and more efficient, especially during inference. Quantization is particularly important for large language models (LLMs) and other complex models, where the trade-off between model size and performance is crucial. It allows for more efficient use of hardware resources and can enable the deployment of larger models on resource-constrained devices. Quantization can be applied to various types of models and often involves techniques like post-training quantization or quantization-aware training to maintain model performance while reducing size and improving inference speed. This process can significantly improve the model's inference speed and reduce memory usage, making it more efficient to deploy and run on resource-constrained devices or environments. It typically involves reducing the precision from floating-point to lower-bit representations like 8-bit integers.
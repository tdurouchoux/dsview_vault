---
type: Concept
---

Chain-of-Thought (CoT) prompting is a technique used to improve the reasoning capabilities of language models by encouraging them to generate intermediate steps in their responses. This is typically done by including phrases like 'think step by step' in the input prompt. CoT prompting makes inference more expensive due to the generation of more output tokens but can lead to more accurate results for complex problems. It is particularly useful for tasks that require a detailed thought process, such as solving puzzles or advanced math problems. This method helps in making the model's thought process more transparent and understandable, akin to how a human would approach problem-solving. This approach significantly improves the capability of LLMs to solve problems without resorting to any model updates and is one of the paradigms that the Graph of Thoughts framework aims to advance.
---
type: Concept
---

Normalization layers are techniques used to standardize the inputs to a neural network, helping to stabilize and accelerate the training process. Common types include Batch Normalization, Layer Normalization, and Instance Normalization, each serving different purposes in maintaining the stability and efficiency of neural network training.
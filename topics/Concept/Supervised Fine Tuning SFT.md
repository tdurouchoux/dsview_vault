---
type: Concept
---

Supervised Fine-Tuning (SFT) is a technique used to adapt pre-trained language models to specific tasks by fine-tuning them on a labeled dataset. This process involves training the model on input-output pairs to improve its performance on particular tasks. In the context of SmolLM2, SFT was used to develop the instruct version of the model, leveraging both public datasets and curated datasets to enhance its capabilities in tasks such as text rewriting, summarization, and function calling.
---
type: Concept
---

Reference-based metrics are evaluation methods that compare the output of a model to a reference or ground truth text. These metrics are commonly used in natural language processing (NLP) tasks such as machine translation, text summarization, and paraphrase generation. The reference text serves as a benchmark against which the model's output is evaluated. Common reference-based metrics include BLEU, ROUGE, and JS divergence, which measure the similarity between the generated text and the reference text using n-grams or other linguistic features.
---
type: Concept
---

A prompting technique used in large language models to improve reasoning by generating intermediate steps or rationales before arriving at a final answer. This method helps in making the decision-making process more transparent and effective. Chain-of-Thought (CoT) is a prompting technique used with large language models to improve their reasoning capabilities. Instead of providing a direct answer, the model is prompted to break down the problem into intermediate steps, mimicking a human-like thought process. This approach helps the model to handle complex problems more effectively and can lead to more accurate and explainable outputs. CoT can be applied in various tasks such as arithmetic, commonsense reasoning, and symbolic reasoning. It involves breaking down complex tasks into intermediate steps, allowing the model to generate more accurate and logical responses by considering each step in a sequence. Chain-of-Thought (CoT) prompting is a technique where intermediate steps of reasoning are included within the prompt, besides the task input/output. This approach significantly improves the capability of LLMs to solve problems without resorting to any model updates. CoT is a foundational concept in the development of more advanced prompting schemes like GoT. Chain-of-thought prompting is a technique used to encourage language models to generate intermediate reasoning steps before arriving at a final answer. This involves including phrases like "think step by step" in the input prompt to guide the model through a more detailed thought process. This technique is particularly useful for complex tasks that require multi-step reasoning and can improve the accuracy and reliability of the model's responses.
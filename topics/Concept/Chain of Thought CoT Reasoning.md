---
type: Concept
---

Chain-of-Thought (CoT) reasoning is a technique used to improve the reasoning abilities of large language models (LLMs). It involves equipping models with the ability to reason about observed history and their actions, which facilitates environment interaction. CoT reasoning has been shown to enhance the decision-making abilities of LLMs by increasing exploration and narrowing the knowing-doing gap. This method is particularly useful for complex problems, as it allows both the model and the user to follow the logical steps involved in arriving at a solution. The faithfulness of the Chain-of-Thought refers to how accurately it reflects the model's actual reasoning process, which is crucial for transparency and alignment with user intentions.
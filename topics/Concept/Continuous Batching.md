---
type: Concept
---

Continuous batching is a technique used to improve the efficiency of inference in transformer models by processing multiple input sequences simultaneously. This approach reduces the overhead of model loading and unloading, leading to faster and more efficient inference. In the context of the Transformers library, continuous batching is introduced to enhance the performance of inference tasks.
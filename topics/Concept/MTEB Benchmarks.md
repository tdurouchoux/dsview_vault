---
type: Concept
---

MTEB (Massive Text Embedding Benchmark) is a comprehensive benchmark suite designed to evaluate the performance of text embedding models across a wide range of tasks, including clustering, reranking, classification, pair classification, semantic textual similarity (STS), and question answering (CQA). The MTEB benchmarks provide a standardized way to compare the performance of different embedding models, making it easier to identify the most suitable model for a given task. WordLlama has been evaluated on the MTEB benchmarks and has shown significant improvements over traditional word models like GloVe 300d.
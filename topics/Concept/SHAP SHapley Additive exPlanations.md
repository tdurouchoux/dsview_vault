---
type: Concept
---

SHAP is a unified method to explain the output of any machine learning model. It provides a way to attribute the model's prediction to each feature, making it easier to understand the impact of each feature on the model's output. SHAP (SHapley Additive exPlanations) is a framework based on Shapley values from game theory to explain the output of machine learning models. It provides a unified method to interpret model predictions by attributing each feature's contribution to the final output. SHAP values are particularly useful for understanding the impact of individual features on model predictions, making complex models more interpretable and transparent.
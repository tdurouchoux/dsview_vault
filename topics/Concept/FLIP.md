---
type: Concept
---

FLIP (Fine-grained Alignment between ID-based Models and Pretrained Language Models) is a method that aligns ID-based recommendation models with LLMs by jointly learning from masked tabular and language data. It involves modality transformation, modality alignment pretraining, and adaptive finetuning to improve cross-modal alignment and recommendation performance.
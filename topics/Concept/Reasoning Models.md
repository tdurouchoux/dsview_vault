---
type: Concept
---

Reasoning models are a type of large language model (LLM) specialized for tasks that require complex, multi-step reasoning. These models are designed to handle tasks such as solving puzzles, advanced mathematics, and coding challenges by generating intermediate reasoning steps. They are particularly useful for tasks that require a detailed thought process, as opposed to simple question-answering tasks. Reasoning models can be developed using various techniques, including inference-time scaling, pure reinforcement learning, supervised fine-tuning combined with reinforcement learning, and distillation. Inference-scaling reasoning models are a new category of large language models that focus on improving performance through additional compute time spent on inference. This approach allows models to handle more complex problems by spending more time on reasoning and processing, rather than just relying on pre-trained knowledge.
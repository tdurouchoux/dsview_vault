---
type: Concept
---

1-bit LLMs (Large Language Models) are a class of models that use binary weights (1-bit) to significantly reduce the model size and computational requirements. These models aim to maintain performance while being more efficient in terms of memory usage and computational power, making them suitable for deployment on resource-constrained devices. The concept includes various techniques and optimizations to achieve efficient inference and training.
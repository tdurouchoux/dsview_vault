---
type: Concept
---

Early fusion is a technique used in multimodal models to integrate different types of data, such as text, vision tokens, audio and video, into a unified model backbone during the pre-training phase. This approach enables the model to jointly pre-train on large amounts of unlabeled text, image, video and audio data, enhancing its ability to understand and process multimodal inputs. Early fusion is a significant advancement in the development of multimodal models, as it allows for more seamless integration of different data types and improves the model's performance on tasks that require understanding of multiple modalities. Ichigo is an example of an early-fusion multimodal model, combining audio and text inputs to facilitate speech understanding and generation.
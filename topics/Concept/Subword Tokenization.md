---
type: Concept
---

Subword tokenization is a method of breaking down text into subword units, such as ‚ñÅinter, national, or ization. It has been widely used but comes with limitations like poor character-level understanding and inflexible compute allocation.
---
type: Concept
---

Model parallelism is a technique in distributed training where different parts of a single model are trained on different devices. This approach is used when a model is too large to fit on a single device, allowing for the training of larger and more complex models.
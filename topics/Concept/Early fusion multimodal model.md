---
type: Concept
---

An early-fusion multimodal model is a type of artificial intelligence model that integrates different types of data (such as audio and text) at the initial stages of processing. This approach allows the model to leverage the strengths of each modality, enabling it to perform tasks that require understanding and generating multiple types of data simultaneously. Ichigo is an example of an early-fusion multimodal model, combining audio and text inputs to facilitate speech understanding and generation.
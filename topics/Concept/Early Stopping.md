---
type: Concept
---

Early stopping is a regularization technique used to prevent overfitting in machine learning models. It involves monitoring the model's performance on a validation set and stopping the training process when the performance starts to degrade. This technique is particularly useful in iterative optimization methods like gradient descent, where continuing training can lead to overfitting and poor generalization to new data.
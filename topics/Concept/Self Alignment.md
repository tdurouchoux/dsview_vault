---
type: Concept
---

Self-Alignment refers to the process where language models align their outputs with desired behaviors or principles without extensive human supervision. This can involve using techniques like self-play, where the model generates its own training data and feedback to improve its performance. Self-alignment aims to create models that are safer, more helpful, and more aligned with human values and intentions.
---
type: Concept
---

Reward hacking occurs when an AI model finds a way to maximize its reward signal without actually performing the intended task or adhering to the task's spirit. This behavior can arise during reinforcement learning when the model exploits loopholes or bugs in the reward structure to achieve high scores without genuine task completion. Reward hacking is undesirable as it can lead to behaviors that do not generalize well and may ignore important safety considerations.
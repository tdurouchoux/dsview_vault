---
type: Concept
---

Reward hacking occurs when an AI model finds a way to maximize its reward signal without actually performing the intended task correctly. This behavior can arise from flaws in the reward structure or training process, leading the model to exploit loopholes or shortcuts. Reward hacking is undesirable because it can result in the model learning behaviors that do not generalize well to other tasks and may even be dangerous if they ignore important safety considerations.
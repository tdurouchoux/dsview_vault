---
type: Concept
---

LoRA, or Low-Rank Adaptation, is a technique used to efficiently fine-tune large language models by applying low-rank updates to the pre-trained model weights. This method reduces the number of trainable parameters, making the fine-tuning process more memory-efficient and faster. LoRA is particularly useful for adapting large models to specific tasks without the need for extensive computational resources. It is widely used in scenarios where resource constraints are a significant concern, such as in edge devices or environments with limited GPU memory. LoRA involves updating only a small set of parameters, reducing memory usage and computational costs while maintaining performance.
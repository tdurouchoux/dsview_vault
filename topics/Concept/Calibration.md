---
type: Concept
---

Calibration in language models refers to the alignment of the model's confidence in its outputs with the actual accuracy of those outputs. The text discusses the importance of calibration in language models, including how calibration can help reduce hallucinations and improve the trustworthiness of the model's outputs. The analysis shows that calibration is a measure of (mis)calibration that is small after pretraining, and that well-trained base models should still generate certain types of errors. The text also discusses the role of calibration in the evaluation of language models, including how calibration can be used to assess the model's ability to generate accurate and reliable responses.
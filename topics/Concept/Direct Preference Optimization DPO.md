---
type: Concept
---

Direct Preference Optimization (DPO) is a method used to fine-tune language models based on human preferences. It involves optimizing the model's responses directly based on feedback, improving the model's performance and relevance in real-world applications. Torchtune supports DPO for various models.
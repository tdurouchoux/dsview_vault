---
type: Concept
---

Pipeline processing blocks are modular components used in data processing pipelines. These blocks can include readers, writers, extractors, filters, statistics collectors, tokenizers, and deduplication tools. Each block processes data in a specific way, taking a generator of documents as input and returning another generator of documents. This modular approach allows for flexible and customizable data processing workflows, enabling users to build complex pipelines tailored to their specific needs.
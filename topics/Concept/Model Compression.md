---
type: Concept
---

Model compression refers to techniques used to reduce the size of machine learning models, making them more suitable for deployment on resource-constrained devices. This includes methods like pruning, quantization, and knowledge distillation, which aim to decrease the computational requirements and memory footprint of models without significantly sacrificing performance.
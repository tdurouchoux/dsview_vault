---
type: Concept
---

Reinforcement Learning (RL) is a machine learning paradigm where an agent learns to make decisions by taking actions in an environment to maximize cumulative rewards. In the context of LLMs, RL is used to fine-tune models by providing rewards based on the quality of the model's responses. This can include accuracy rewards for verifiable tasks like coding and math, and format rewards to ensure responses follow a specific structure. RL can help induce reasoning capabilities in models without the need for supervised fine-tuning. Reinforcement Learning (RL) is a training method used to improve the performance of language models. It involves using reward signals to guide the model's learning process. In the context of DeepSeek-R1, RL is used to create an interim reasoning model and to generate supervised fine-tuning (SFT) reasoning examples. This method allows the model to excel at reasoning tasks and improve its overall performance. Unlike supervised learning, reinforcement learning does not rely on labeled data; instead, it learns from the consequences of its actions through a trial-and-error process. The core components of reinforcement learning include the agent (the learner or decision maker), the environment (the external system the agent interacts with and learns from), actions (choices the agent can make), states (conditions the agent finds itself in), and rewards (feedback from the environment based on the actions taken). Reinforcement learning algorithms can be categorized into value-based methods (like Q-learning), policy-based methods (like Proximal Policy Optimization), and actor-critic methods. Applications of reinforcement learning include robotics, game playing (such as AlphaGo), resource management, and autonomous driving.
---
type: Concept
---

Pre-training involves training the Gemini models on a large dataset to build a foundation of knowledge. Post-training involves further training on specific tasks or datasets to improve performance on those tasks. This includes supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) using a reward model.
---
type: Concept
---

Small Language Models (SLMs) are compact versions of large language models that require fewer computational resources while still offering robust language understanding and generation capabilities. SLMs are designed to be more efficient and accessible, making them suitable for deployment on edge devices or in environments with limited resources. Despite their smaller size, SLMs can still achieve impressive performance on various natural language processing tasks.
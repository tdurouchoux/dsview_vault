---
type: Concept
---

Chain-of-Thought (CoT) is a reasoning approach used in large language models where the model generates intermediate steps or thoughts before arriving at a final answer. This method aims to improve the model's ability to handle complex tasks by breaking them down into smaller, more manageable steps. CoT can enhance the transparency and interpretability of the model's decision-making process. However, it can also lead to hallucinations, where the model generates incorrect or fabricated information as part of its reasoning chain. Chain-of-Thought (CoT) prompting is a technique used to improve the reasoning capabilities of language models by encouraging them to generate intermediate steps in their responses. This is typically done by including phrases like 'think step by step' in the input prompt. CoT prompting makes inference more expensive due to the generation of more output tokens but can lead to more accurate results for complex problems. It is particularly useful for tasks that require a detailed thought process, such as solving puzzles or advanced math problems. This method helps in making the model's thought process more transparent and understandable, akin to how a human would approach problem-solving. This approach significantly improves the capability of LLMs to solve problems without resorting to any model updates and is one of the paradigms that the Graph of Thoughts framework aims to advance.
---
type: Concept
---

Gradient compression is a technique used to reduce the communication overhead in distributed training by compressing the gradients before transmitting them between devices. This can significantly speed up the training process and reduce the amount of data that needs to be transferred.
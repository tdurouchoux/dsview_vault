---
type: Concept
---

Gradient compression is a technique used to reduce the communication overhead in distributed training by compressing the gradients before they are sent across the network. This can significantly speed up the training process and reduce bandwidth usage.
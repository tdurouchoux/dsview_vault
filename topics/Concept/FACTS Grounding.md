---
type: Concept
---

FACTS Grounding is a benchmark designed to evaluate the factual accuracy and grounding of large language models (LLMs). It assesses the ability of LLMs to generate responses that are factually accurate and grounded in provided source material, avoiding hallucinations. The benchmark includes a dataset with various examples across different domains and uses multiple LLM judges to evaluate responses.
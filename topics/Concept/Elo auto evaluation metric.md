---
type: Concept
---

The Elo auto-evaluation metric is a method inspired by the Elo rating system used in chess to evaluate the performance of AI-generated hypotheses and research proposals. It involves ranking tournaments and self-play-based scientific debates to assess the quality and novelty of outputs. Higher Elo ratings correlate with higher-quality results, making it a useful tool for auto-evaluation in AI systems.
---
type: Concept
---

Graph explanations refer to techniques and methods used to interpret and explain the predictions made by Graph Neural Networks. These explanations help to understand why a GNN made a particular prediction, which nodes or edges were most influential, and how the graph structure contributes to the model's decisions. Graph explanations are important for building trust, debugging, and gaining insights from GNNs.
---
type: Concept
---

Crowdsourced evaluation involves collecting feedback and preferences from a large number of users to assess the performance of AI systems. This approach helps in understanding how humans interact with and evaluate these systems in real-world scenarios, providing a more diverse and comprehensive assessment than traditional benchmarks.
---
type: Concept
---

Nondeterminism in LLM Inference refers to the variability in outputs generated by large language models (LLMs) when given the same input multiple times, even under seemingly deterministic conditions. This phenomenon arises due to the probabilistic nature of sampling processes involved in generating text, as well as underlying computational factors such as floating-point arithmetic and concurrent execution in hardware.
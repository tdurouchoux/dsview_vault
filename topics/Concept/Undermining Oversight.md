---
type: Concept
---

Undermining oversight involves an AI model subtly manipulating evaluation or monitoring systems to avoid detection or to reduce the effectiveness of oversight mechanisms. This evaluation tests the model's ability to deceive oversight systems, such as by providing misleading feedback or avoiding scrutiny. The goal is to ensure that models do not subvert the systems designed to keep them safe and aligned with human values.
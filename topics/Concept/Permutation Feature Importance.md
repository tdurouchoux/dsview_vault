---
type: Concept
---

Permutation feature importance is a model-agnostic method used to determine the importance of features in a machine learning model. It involves shuffling a feature's values and measuring the decrease in the model's performance. The drop in performance indicates the feature's importance, with more significant drops suggesting higher importance. This method is useful for understanding which features contribute most to the model's predictions and can aid in feature selection and model interpretation.
---
type: Concept
---

Retrieval Augmented Generation (RAG) is a technique that enhances the performance of large language models (LLMs) by providing them with additional context retrieved from external sources. This context can improve the factuality and verifiability of the model's responses, especially in open-domain question answering tasks. The context can be in the form of snippets or long-form text, which the model synthesizes with the query to generate an answer. However, RAG systems can exhibit undesirable traits such as confidently predicting incorrect answers, being distracted by unrelated information, and failing to properly extract answers from long text snippets. Retrieval-Augmented Generation (RAG) is a technique that combines retrieval mechanisms with generative models to improve the context and relevance of generated outputs. In the context of code, RAG can be used to retrieve relevant code snippets or context for tasks such as code completion, editing, or explanation. This approach enhances the performance of AI-powered software engineering tools and coding agents by providing more accurate and contextually relevant suggestions. A method that integrates external information into AI models to improve their responses. Traditional RAG methods often rely on batch processing and static data summarization, which can be inefficient for frequently changing data. Retrieval-Augmented Generation (RAG) is a concept in AI research that combines retrieval-based methods with generative models to improve the accuracy and relevance of generated text. In RAG, a retrieval system first fetches relevant information from a large corpus of documents, which is then used by a generative model to produce more informed and contextually appropriate responses. This approach enhances the quality of AI-generated content by grounding it in verified and relevant information, making it particularly useful for research and information retrieval tasks.
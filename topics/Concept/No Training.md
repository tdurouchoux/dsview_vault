---
type: Concept
---

No Training refers to optimization strategies that bridge image and text representations using pre-trained image and text models or adapt pre-trained multi-modal models to new downstream tasks without additional training. This approach leverages pre-trained models to generate captions for input images or perform similarity-based searches using a small dataset of ground-truth multi-modal pairs.
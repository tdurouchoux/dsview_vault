---
type: Concept
---

Transformer decoders are a type of neural network architecture used in the Gemini models. They are enhanced with improvements in architecture and model optimization to enable stable training at scale and optimized inference on Googleâ€™s Tensor Processing Units. They are trained to support 32k context length, employing efficient attention mechanisms like multi-query attention.
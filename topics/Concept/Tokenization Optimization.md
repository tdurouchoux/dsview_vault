---
type: Concept
---

Tokenization optimization refers to the techniques used to improve the efficiency and effectiveness of the tokenization process in machine learning models. In the context of SmolVLM, tokenization optimizations include increasing the pixel shuffle rate and using special tokens to represent sub-image separators more efficiently. These optimizations lead to better model stability during training and improved quality of results, making the models more efficient and effective in processing multimodal data.
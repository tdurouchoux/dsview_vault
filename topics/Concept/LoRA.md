---
type: Concept
---

LoRA, or Low-Rank Adaptation, is a technique used in fine-tuning large language models. It involves updating only a small number of trainable parameters, which reduces memory usage and computational requirements. LoRA is supported in torchtune for various models and training scenarios.
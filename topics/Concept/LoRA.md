---
type: Concept
---

LoRA, or Low-Rank Adaptation, is a technique used in fine-tuning large language models. It involves updating only a small set of parameters, reducing memory usage and computational costs while maintaining performance. LoRA is particularly useful for adapting pre-trained models to specific tasks without the need for full fine-tuning.
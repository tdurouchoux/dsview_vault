---
type: Model
---

Graph Neural Networks (GNNs) are a powerful technique that leverages both the connectivity of graphs and the input features on nodes and edges. GNNs can make predictions for graphs as a whole, for individual nodes, or for potential edges. They encode a graph's discrete, relational information in a continuous way, allowing it to be included naturally in other deep learning systems. Graph Neural Networks (GNNs) are general architectures that represent flexible models for graph learning. Developed by Peter Battaglia and colleagues, GNNs have been extended with concepts like attention, allowing models to focus on important parts of the input data. They are neural networks designed to operate on graph-structured data, leveraging the structure and properties of graphs, where data is represented as nodes and edges, to perform various prediction tasks. GNNs have been developed to handle graph-level, node-level, and edge-level tasks, and have applications in areas such as molecular discovery, physics simulations, fake news detection, traffic prediction, and recommendation systems. They are built using components like message passing neural networks and graph nets architectures, and can be adapted to different types of graph data and attributes.
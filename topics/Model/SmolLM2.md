---
type: Model
---

SmolLM2 is a family of compact language models available in three sizes: 135M, 360M, and 1.7B parameters. They are designed to be lightweight enough to run on-device while being capable of solving a wide range of tasks. The models have shown significant advances in instruction following, knowledge, reasoning, and mathematics. They were trained on a diverse dataset combination, including FineWeb-Edu, DCLM, The Stack, and new mathematics and coding datasets. The instruct version was developed through supervised fine-tuning (SFT) and Direct Preference Optimization (DPO) using UltraFeedback.
---
type: Model
---

SmolVLM-256M is a Vision Language Model (VLM) with 256 million parameters, making it the smallest VLM ever released. Despite its compact size, it is capable of performing various multimodal tasks such as image captioning, document question answering, and basic visual reasoning. It is designed for efficiency and can be used in constrained environments like consumer laptops or browser-based inference.
---
type: Model
---

Llama 4 Scout is a 17 billion active parameter model with 16 experts, designed for multimodal intelligence. It is optimized for efficiency, fitting on a single NVIDIA H100 GPU, and offers an industry-leading context window of 10 million tokens. This model excels in tasks such as multi-document summarization, parsing extensive user activity, and reasoning over vast codebases. It uses a mixture-of-experts (MoE) architecture, which improves inference efficiency by activating only a subset of total parameters during serving, thereby reducing model serving costs and latency. Llama 4 Scout is also best-in-class on image grounding, enabling precise visual question answering and better understanding of user intent and localization of objects of interest.
---
type: Model
---

Mistral Small 3.1 is a lightweight, versatile AI model designed for a wide range of generative AI tasks. It features improved text performance, multimodal understanding, and an expanded context window of up to 128k tokens. The model is optimized for low-latency, high-speed inference, capable of handling 150 tokens per second. It supports various applications including conversational assistance, image understanding, and function calling. The model is available under an Apache 2.0 license and can be fine-tuned for specialized domains, making it suitable for both enterprise and consumer-grade applications. It is designed to run efficiently on hardware like a single RTX 4090 or a Mac with 32GB RAM, making it accessible for on-device use cases.
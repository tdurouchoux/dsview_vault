---
type: Model
---

BitNet b1.58 is a model architecture designed for 1-bit Large Language Models (LLMs). It is optimized for efficient inference, particularly on CPUs, and is part of the BitNet family of models. The b1.58 designation indicates that the model uses 1.58 bits per weight, allowing for significant reductions in model size and computational requirements while maintaining performance. This model architecture is designed to run efficiently on local devices, achieving speeds comparable to human reading (5-7 tokens per second) on a single CPU. BitNet b1.58 2B4T is an open-source, native 1-bit Large Language Model (LLM) with 2 billion parameters. It is designed for efficiency, offering reduced memory footprint, energy consumption, and decoding latency while maintaining performance comparable to leading full-precision LLMs of similar size. The model has been trained on a corpus of 4 trillion tokens and evaluated across various benchmarks including language understanding, mathematical reasoning, coding proficiency, and conversational ability.
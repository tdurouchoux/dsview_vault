---
type: Model
---

Ichigo is an early-fusion, audio and text, multimodal model based on the Llama3 architecture. It is designed to listen to human speech and respond verbally, making it a speech-enabled language model. The model undergoes a three-phase training process to enhance its capabilities in multilingual speech understanding, maintaining original performance, and handling inaudible inputs and multi-turn conversations.
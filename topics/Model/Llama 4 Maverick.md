---
type: Model
---

Llama 4 Maverick is a 17 billion active parameter model with 128 experts, designed for advanced multimodal applications. It outperforms other models in its class on various benchmarks, including reasoning, coding, and image understanding. The model uses a mixture-of-experts (MoE) architecture and is optimized for both performance and cost-efficiency, fitting on a single NVIDIA H100 host.
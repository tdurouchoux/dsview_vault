---
already_read: true
link: https://github.com/deepseek-ai/DeepSeek-OCR/
read_priority: 0
relevance: 5
source: Alpha Signal
tags:
- Computer_Vision
- Natural_Language_Processing
type: Content
upload_date: '2025-10-25'
---

https://github.com/deepseek-ai/DeepSeek-OCR/
## Summary

DeepSeek-OCR is a model designed for optical character recognition (OCR) with a focus on visual-text compression. It is built to explore the role of vision encoders from an LLM-centric perspective. The model supports various resolution modes, including native resolutions (Tiny, Small, Base, Large) and dynamic resolution (Gundam). It can be used for tasks such as document conversion to markdown, general OCR, figure parsing, and image description. The model is available for inference using vLLM and Transformers libraries. Installation instructions and usage examples are provided in the repository. The project acknowledges contributions from various models and benchmarks and includes a citation for the associated paper.
## Links

- [DeepSeek-OCR Paper](https://github.com/deepseek-ai/DeepSeek-OCR/blob/main/DeepSeek_OCR_paper.pdf) : The PDF of the DeepSeek-OCR paper, providing detailed information about the model and its capabilities.
- [DeepSeek-OCR Arxiv Paper](https://arxiv.org/abs/2510.18234) : The Arxiv paper link for DeepSeek-OCR, offering insights into the research and development behind the model.
- [DeepSeek-OCR Hugging Face](https://huggingface.co/deepseek-ai/DeepSeek-OCR) : The Hugging Face page for DeepSeek-OCR, providing access to the model and related resources.

## Topics

![[topics/Model/DeepSeek OCR]]

![[topics/Library/vLLM]]
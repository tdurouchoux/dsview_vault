---
already_read: true
link: https://github.com/iyaja/llama-fs
read_priority: 0
relevance: 5
source: null
tags:
- AI_agent
type: Content
upload_date: '2025-05-04'
---

https://github.com/iyaja/llama-fs
## Summary

LlamaFS is a self-organizing file system that uses the Llama 3 model to automatically rename and organize files based on their content and conventions like time. It operates in two modes: batch mode for one-time organization and watch mode for continuous, proactive learning and organization. The system supports various file types, including images and audio, and offers an "incognito mode" for local processing via Ollama, ensuring privacy. Built with a Python backend and an Electron frontend, LlamaFS is designed to be fast and user-friendly. It addresses common file management challenges and has potential future features like finding and removing old/unused files. Installation requires Python 3.10+, pip, and specific API keys for Groq and AgentOps, with optional Ollama integration for incognito mode. Usage involves running a FastAPI server and querying it with file paths and instructions.
## Links

- [AgentOps](https://agentops.ai/?utm_source=llama-fs) : AgentOps is a monitoring and logging tool used by LlamaFS to track latency, cost per session, and provide session replays. It's mentioned in the installation section as an optional dependency for logging and monitoring purposes.
- [Groq Console](https://console.groq.com/keys) : Groq Console is where users can obtain API keys for Groq, which is used by LlamaFS for fast cloud inference. It's mentioned in the installation section as a requirement for setting up the project.

## Topics

![](topics/Model/LLaMA)

![](topics/Concept/Self%20organizing%20file%20system)

![](topics/Library/Groq)

![](topics/Library/Moondream)

![](topics/Library/Electron)

![](topics/Library/FastAPI)

![](topics/Library/AgentOps)

![](topics/Tool/Ollama)

![](topics/Model/Whisper)
---
already_read: true
link: https://github.com/iyaja/llama-fs
read_priority: 0
relevance: 5
source: null
tags:
- Large_Language_Model
type: Content
upload_date: '2025-05-04'
---

https://github.com/iyaja/llama-fs
## Summary

LlamaFS is a self-organizing file system that uses the Llama 3 model to automatically rename and organize files based on their content and conventions like time. It supports various file types, including images and audio, and operates in two modes: batch and watch. In batch mode, it suggests a file structure for a given directory, while in watch mode, it actively learns from user actions to organize files proactively. The system prioritizes privacy with an "incognito mode" that routes requests through Ollama instead of Groq. Built with a Python backend and an Electron frontend, LlamaFS is designed to be fast and user-friendly, with most file operations processed in under 500ms. Future plans include finding and removing old/unused files. Installation requires Python 3.10 or higher, pip, and specific API keys for Groq and AgentOps. The project is open-source under the MIT license.
## Links

- [AgentOps](https://agentops.ai/?utm_source=llama-fs) : AgentOps is a monitoring and logging tool used by LlamaFS to track latency, cost per session, and provide session replays. It's mentioned in the context of installation and usage for LlamaFS.
- [Groq Console](https://console.groq.com/keys) : Groq is used for fast cloud inference in LlamaFS. This link leads to the Groq console where users can obtain API keys necessary for using Groq's services with LlamaFS.

## Topics

![](topics/Tool/LlamaFS)

![](topics/Platform/Groq)

![](topics/Model/Llama3)

![](topics/Model/Moondream)

![](topics/Concept/Ollama)

![](topics/Model/Whisper)
---
already_read: true
link: https://github.com/google-ai-edge/LiteRT
read_priority: 0
relevance: 5
source: null
tags:
- Deep_Learning
- Large_Language_Model
type: Content
upload_date: '2026-01-17'
---

https://github.com/google-ai-edge/LiteRT
## Summary

LiteRT is Google's on-device framework for high-performance machine learning (ML) and generative AI (GenAI) deployment on edge platforms. It is the successor to TensorFlow Lite and offers advanced GPU/NPU acceleration, superior ML & GenAI performance, and efficient conversion, runtime, and optimization capabilities.

Key features include:
- **New LiteRT Compiled Model API**: Streamlines development with automated accelerator selection, true async execution, and efficient I/O buffer handling.
- **Unified NPU Acceleration**: Seamless access to NPUs from major chipset providers with a consistent developer experience.
- **Best-in-class GPU Performance**: State-of-the-art GPU acceleration for on-device ML with zero-copy and minimized latency across various GPU buffer types.
- **Superior Generative AI Inference**: Simplest integration with the best performance for GenAI models.

LiteRT supports a wide range of platforms, including Android, iOS, Linux, macOS, Windows, Web, and IoT devices. It offers various paths for developers based on their goals, such as converting PyTorch models, running pre-trained models, maximizing performance, and working with Generative AI.

The framework is part of a larger ecosystem of tools for on-device machine learning, including LiteRT Samples, AI Edge Torch Converter, Torch Generative API, LiteRT-LM, XNNPACK, and MediaPipe. LiteRT is licensed under the Apache-2.0 License and welcomes contributions from the community.
## Links

- [LiteRT LM](https://github.com/google-ai-edge/litert-lm) : A library to efficiently run Large Language Models (LLMs) across edge platforms, built on top of LiteRT.
- [LiteRT Documentation](https://ai.google.dev/edge/litert/next/overview) : Official documentation for LiteRT, providing detailed information on its features, installation, and usage.
- [LiteRT NPU Acceleration](https://ai.google.dev/edge/litert/next/npu) : Information on LiteRT's NPU acceleration capabilities, offering seamless access to NPUs from major chipset providers.
- [LiteRT Get Started Guide](https://ai.google.dev/edge/litert/next/get_started) : A comprehensive guide to setting up your application with LiteRT, including installation and basic usage instructions.
- [LiteRT Samples](https://github.com/google-ai-edge/litert-samples) : A collection of LiteRT sample apps demonstrating various features and use cases.

## Topics

![[topics/Tool/LiteRT]]

![[topics/Tool/AI Edge Torch Converter]]

![[topics/Tool/Torch Generative API]]

![[topics/Tool/LiteRT LM]]

![[topics/Tool/XNNPACK]]
---
already_read: false
link: https://lastexam.ai/
read_priority: 2
relevance: 0
source: Blef
tags:
- Large_Language_Model
- AI_agent
type: Content
upload_date: '2025-02-14'
---

https://lastexam.ai/
## Summary

The content introduces Humanity's Last Exam (HLE), a challenging multi-modal benchmark designed to measure the capabilities of large language models (LLMs) at the frontier of human knowledge. Key points include:

1. **Purpose and Design**: HLE aims to address the saturation of existing benchmarks by providing a more difficult set of 2,500 questions across over a hundred subjects, created by nearly 1,000 subject experts from over 500 institutions worldwide.

2. **Dataset and Examples**: The dataset includes diverse and challenging questions, with examples provided in various fields such as Classics and Ecology. The questions are designed to be at the cutting edge of academic knowledge.

3. **Quantitative Results**: Current frontier models achieve low accuracy on HLE, indicating significant room for improvement. The benchmark also measures calibration error to assess how well models recognize their uncertainty.

4. **Future Model Performance**: While current models perform poorly, rapid advancements in AI suggest that models could achieve over 50% accuracy on HLE by the end of 2025. High accuracy on HLE would demonstrate expert-level performance on structured academic problems but not necessarily autonomous research capabilities.

5. **Impact**: HLE provides a common reference point for assessing AI capabilities, enabling more informed discussions about AI development, potential risks, and necessary governance measures.

6. **Related Articles**: The content includes references to articles from The New York Times and Reuters, highlighting the significance and potential impact of HLE.

7. **Contact Information**: For inquiries or feedback, the contact email is provided as agibenchmark@safe.ai.
## Links

- [Humanity's Last Exam Dataset](https://huggingface.co/datasets/cais/hle) : The Hugging Face dataset page for Humanity's Last Exam, providing access to the dataset used for evaluating advanced language models.
- [Humanity's Last Exam Results](https://scale.com/blog/humanitys-last-exam-results) : A blog post detailing the results of Humanity's Last Exam, showcasing the performance of various AI models on the challenging benchmark.
- [Humanity's Last Exam Leaderboard](https://scale.com/leaderboard/humanitys_last_exam) : The leaderboard for Humanity's Last Exam, displaying the rankings of different AI models based on their performance on the benchmark.

## Topics

![](topics/Dataset/Humanity%20s%20Last%20Exam%20HLE)
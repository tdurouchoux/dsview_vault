---
already_read: false
link: https://github.com/unslothai/unsloth
read_priority: 3
relevance: 0
source: Alpha Signal
tags:
- Large_Language_Model
- AI_agent
type: Content
upload_date: '2025-02-18'
---

https://github.com/unslothai/unsloth
## Summary

Unsloth is a tool designed for fine-tuning and reinforcement learning of large language models (LLMs). It supports a variety of models including OpenAI's gpt-oss, Qwen3, Llama 4, DeepSeek-R1, Gemma 3, and TTS. The tool is notable for its performance, offering 2x faster training with 70% less VRAM usage compared to traditional methods. It supports a range of features such as full-finetuning, pretraining, 4-bit, 16-bit, and 8-bit training, and is compatible with various transformer-style models including TTS, STT, multimodal, diffusion, BERT, and more. Unsloth is designed to work on NVIDIA GPUs since 2018 and supports both Linux and Windows operating systems. The tool also includes a variety of installation options, including pip, Conda, and Docker, and provides detailed documentation and guides for users. Additionally, Unsloth supports reinforcement learning techniques such as DPO, GRPO, PPO, Reward Modelling, and Online DPO, and includes performance benchmarks for various models and contexts. The project is open-source and has a community of contributors.
## Links

- [Unsloth Documentation](https://docs.unsloth.ai/) : The official documentation for Unsloth, providing detailed guides on installation, usage, and advanced features for fine-tuning and reinforcement learning with LLMs.
- [Unsloth Blog](https://unsloth.ai/blog) : The official blog for Unsloth, featuring articles and updates on new features, benchmarks, and tutorials for using Unsloth with various models and frameworks.
- [Unsloth GitHub Repository](https://github.com/unslothai/unsloth) : The GitHub repository for Unsloth, containing the source code, issue tracking, and community contributions for the Unsloth project.

## Topics

![[topics/Concept/LoRA Low Rank Adaptation]]

![[topics/Concept/Reinforcement Learning from Human Feedback RLHF]]

![[topics/Concept/Quantization]]

![[topics/Library/Unsloth]]
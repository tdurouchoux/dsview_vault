---
already_read: false
link: https://github.com/unslothai/unsloth
read_priority: 3
relevance: 0
source: Alpha Signal
tags:
- Large_Language_Model
- AI_agent
type: Content
upload_date: '2025-02-18'
---

https://github.com/unslothai/unsloth
## Summary

Unsloth is a tool designed for fine-tuning and reinforcement learning of large language models (LLMs). It supports various models such as OpenAI gpt-oss, Qwen3, Llama 4, DeepSeek-R1, Gemma 3, and TTS, enabling training that is 2x faster with 70% less VRAM. Key features include support for full fine-tuning, pretraining, 4-bit, 16-bit, and 8-bit training, as well as compatibility with transformer-style models like TTS, STT, multimodal, diffusion, BERT, and more. The tool is optimized for NVIDIA GPUs since 2018 and works on both Linux and Windows. It offers significant performance improvements, such as 2x faster training and up to 80% less VRAM usage for various models. The documentation provides detailed instructions for installation, usage, and advanced features like saving to GGUF, checkpointing, and evaluation. Unsloth also supports reinforcement learning techniques like DPO, GRPO, PPO, and reward modeling. The tool is open-source and has a community of contributors.
## Links

- [Unsloth Documentation](https://docs.unsloth.ai/) : Official documentation for Unsloth, providing detailed guides on saving to GGUF, checkpointing, evaluation, and more. It supports Hugging Face's TRL, Trainer, Seq2SeqTrainer, and PyTorch code.
- [Unsloth Blog](https://unsloth.ai/blog) : Blog containing articles and updates about Unsloth, including performance benchmarks, model support, and new features.
- [Unsloth GitHub Repository](https://github.com/unslothai/unsloth) : The main GitHub repository for Unsloth, containing the source code, installation instructions, and additional resources for fine-tuning and reinforcement learning for LLMs.

## Topics

![](topics/Library/Unsloth)
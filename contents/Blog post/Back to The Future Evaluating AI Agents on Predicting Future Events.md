---
already_read: false
link: https://huggingface.co/blog/futurebench
read_priority: 3
relevance: 0
source: Data Points
tags:
- AI_agent
- Model_evaluation
type: Content
upload_date: '2025-09-17'
---

https://huggingface.co/blog/futurebench
## Summary

The document discusses the evaluation of AI agents' ability to predict future events, highlighting the limitations of current AI benchmarks that focus on past knowledge. It introduces FutureBench, a benchmark that evaluates AI agents on their forecasting capabilities, which is inherently verifiable and resistant to data contamination. FutureBench uses two approaches to generate prediction questions: News-Generated Questions and Polymarket Integration. The benchmark operates on three levels of evaluation: Framework Comparison, Tool Performance, and Model Capabilities. Initial results show that agentic models perform better than simple language models, with distinct reasoning patterns among different models. The document also discusses the limitations and future directions of FutureBench, emphasizing the need for community feedback. References to related works and additional articles are provided.
## Links

- [FutureBench Interactive Leaderboard](https://huggingface.co/spaces/futurebench/FutureBench/) : The FutureBench Interactive Leaderboard is a live leaderboard that allows users to explore and compare the performance of different AI agents on the FutureBench benchmark. The benchmark evaluates AI agents on their ability to predict future events, using a combination of news-generated questions and questions from prediction markets. The leaderboard provides a transparent and objective measure of model performance, allowing users to see how different models compare on a range of prediction tasks.
- [DeepResearch](https://openai.com/index/introducing-deep-research/) : DeepResearch is a tool developed by OpenAI that is used for market analysis and strategic planning. It is mentioned in the context of FutureBench as an example of a tool that is already used for information collection and synthesis, which are key capabilities that FutureBench aims to measure. The quality of information collection is strongly correlated with decision-making effectiveness, and FutureBench is inspired by this evaluation process.

## Topics

![[topics/Model/DeepSeek v3)]]

![[topics/Concept/SmolAgents)]]

![[topics/Concept/FutureBench)]]

![[topics/Tool/Firecrawl)]]

![[topics/Tool/Tavily)]]

![[topics/Concept/Prediction Markets)]]

![[topics/Concept/Agentic Frameworks)]]
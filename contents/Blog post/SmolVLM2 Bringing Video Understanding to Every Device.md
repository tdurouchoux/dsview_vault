---
already_read: false
link: https://huggingface.co/blog/smolvlm2
read_priority: 3
relevance: 0
source: Data Points
tags:
- Computer_Vision
- Large_Language_Model
type: Content
upload_date: '2025-02-21'
---

https://huggingface.co/blog/smolvlm2
## Summary

SmolVLM2 introduces efficient video understanding models in three sizes: 2.2B, 500M, and 256M parameters. The 2.2B model excels in vision and video tasks, outperforming existing models in benchmarks like Video-MME. The smaller models, 500M and 256M, offer comparable video understanding capabilities with significantly fewer parameters. SmolVLM2 is designed to run on various devices, from phones to servers, and is available with MLX and Transformers support from day one. The release includes demo applications such as an iPhone app for local video analysis, VLC media player integration for semantic video navigation, and a Video Highlight Generator for summarizing long-form videos. Fine-tuning tutorials and citation information are also provided.
## Links

- [SmolVLM2 Collection with Models and Demos](https://huggingface.co/collections/HuggingFaceTB/smolvlm2-smallest-video-lm-ever-65ab6b5e84bf8aaa60cb17c7) : Collection of SmolVLM2 models and demos showcasing their capabilities in video understanding.
- [Video-MME Benchmark](https://video-mme.github.io/home_page.html) : Comprehensive benchmark for video understanding, covering diverse video types and durations with expert annotations.
- [SmolVLM2 Video Highlight Generator](https://huggingface.co/spaces/HuggingFaceTB/SmolVLM2-HighlightGenerator) : Application that extracts significant moments from long-form videos, tested on soccer matches and other lengthy events.

## Topics

![](topics/Model/SmolVLM2)

![](topics/Concept/Video%20MME)

![](topics/Library/Transformers)

![](topics/Library/MLX)
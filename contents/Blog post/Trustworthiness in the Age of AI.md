---
already_read: true
link: https://jfkirk.github.io/posts/trustworthiness-ai/
read_priority: 1
relevance: 0
source: Data Elixir
tags:
- Large_Language_Model
- AI_regulation
type: Content
upload_date: '2024-12-28'
---

https://jfkirk.github.io/posts/trustworthiness-ai/
## Summary

The text discusses the evolution of trust in computing, from the infallible "Calculator" to the fallible "Algorithm," and now to the emergent "AI." It highlights the shift from trusting computers for precise calculations to trusting algorithms for probabilistic predictions, and now to trusting AI for seemingly intentional and knowledgeable interactions. The author emphasizes that AI, particularly Large Language Models (LLMs), is neither methodical nor calculating but is fallible, noisy, and influenced by emergent behavior. Unlike traditional computers, AI demands trust directly, rather than proxying it to its creators. The author argues that AI's convincing nature and the subtlety of its errors make it challenging to discern its limits and errors, leading to a collapse in the traditional model of trust. The text concludes by stressing the importance of engineers understanding AI's properties, evaluating its use, and ensuring they are trustworthy in building and deploying AI systems.
## Links

- [Gell-Mann Amnesia Effect](https://en.wiktionary.org/wiki/Gell-Mann_Amnesia_effect) : The Gell-Mann Amnesia effect is a cognitive bias where one dismisses facts presented in media that contradict one's worldview, yet continues to consume that media, forgetting that it has misled them before.
- [Why Are We Using LLMs as Calculators?](https://vickiboykis.com/2024/11/09/why-are-we-using-llms-as-calculators/) : An article discussing the limitations of using large language models (LLMs) as calculators and the potential pitfalls of relying on them for precise computations.

## Topics

![](topics/Concept/Retrieval%20Augmented%20Generation)

![](topics/Concept/Chain%20of%20Thought)
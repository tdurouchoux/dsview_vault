---
already_read: false
link: https://eugeneyan.com//writing/recsys-llm/
read_priority: 4
relevance: 0
source: Data Elixir
tags:
- Large_Language_Model
type: Content
upload_date: '2025-03-19'
---

https://eugeneyan.com//writing/recsys-llm/
## Summary

The content discusses advancements in recommendation systems and search in the era of large language models (LLMs), focusing on model architectures, data generation, training paradigms, and unified frameworks. Key points include:

1. **LLM/multimodality-augmented model architecture**: Recommendation models are increasingly adopting language models and multimodal content to overcome traditional limitations of ID-based approaches. Examples include Semantic IDs (YouTube), M3CSR (Kuaishou), FLIP (Huawei), beeFormer, CALRec (Google), and EmbSum (Meta).

2. **LLM-assisted data generation and analysis**: LLMs are used to enrich data, tackle data scarcity, and enhance the quality of search and recommendations. Examples include Recommendation Quality Improvement (Bing), Expected Bad Match (Indeed), Query Understanding (Yelp), Query Recommendations (Spotify), and Playlist Search (Amazon).

3. **Scaling Laws, transfer learning, distillation, LoRAs**: Trends include exploring scaling laws, using knowledge distillation, applying cross-domain transfer learning, and parameter-efficient fine-tuning techniques such as LoRAs. Examples include Scaling Laws, PrepRec, E-CDCTR (Meituan), Bridging the Gap (YouTube), Self-Auxiliary Distillation (Google), DLLM2Rec, MLoRA (Alibaba), Taming One-Epoch (Pinterest), and Sliding Window Training (Netflix).

4. **Unified architectures for search and recommendations**: There is a shift towards unified system architectures that blend search and recommendations, drawing inspiration from foundation models. Examples include Bridging Search & Recommendations (Spotify), 360Brew (LinkedIn), UniCoRn (Netflix), Unified Embeddings (Etsy), Embedding Long Tail (Best Buy), User Behavioral Service (YouTube), and Modern Ranking Platform (Zalando).

The content concludes that recent efforts show more promise in applying LLMs to recommendations and search, with tangible benefits in increasing performance while reducing cost and effort.
## Links

- [Behavior Sequence Transformer for E-Commerce Recommendation in Alibaba](https://arxiv.org/abs/1905.06874) : This paper discusses the application of transformer models in e-commerce recommendation systems at Alibaba, focusing on sequential recommendation tasks.
- [Better Generalization with Semantic IDs: A Case Study in Ranking for Recommendations](https://doi.org/10.48550/arXiv.2306.08121) : This paper explores the use of semantic IDs to improve the generalization of recommendation systems, particularly in ranking tasks.
- [Leveraging LLM Generated Labels to Reduce Bad Matches in Job Recommendations](https://doi.org/10.1145/3640457.3688043) : This paper discusses how LLM-generated labels can be used to filter out poor job matches in recommendation systems, improving the quality of job recommendations.

## Topics

![](topics/Concept/Semantic%20IDs)

![](topics/Concept/M3CSR)

![](topics/Concept/FLIP)

![](topics/Concept/beeFormer)

![](topics/Concept/CALRec)

![](topics/Concept/EmbSum)

![](topics/Concept/Recommendation%20Quality%20Improvement)

![](topics/Concept/Expected%20Bad%20Match)

![](topics/Concept/Query%20Understanding)

![](topics/Concept/Query%20Recommendations)
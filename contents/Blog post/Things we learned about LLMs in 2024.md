---
already_read: true
link: https://simonwillison.net/2024/Dec/31/llms-in-2024/
read_priority: 0
relevance: 3
source: Data Elixir
tags:
- Large_Language_Model
- AI_agent
type: Content
upload_date: '2025-01-08'
---

https://simonwillison.net/2024/Dec/31/llms-in-2024/
## Summary

The article reviews significant advancements in Large Language Models (LLMs) throughout 2024, highlighting key trends and breakthroughs. Notable points include the breaking of the GPT-4 barrier by multiple organizations, the ability to run GPT-4 class models on personal laptops, and a substantial drop in LLM prices due to increased competition and efficiency. Multimodal capabilities, including vision, audio, and video, became more common, with live voice and camera modes emerging as groundbreaking features. The article also discusses the commoditization of prompt-driven app generation, the short-lived universal access to top-tier models, and the ongoing challenges with "agents" and prompt injection. Evaluations (evals) were emphasized as crucial for building reliable LLM applications. Apple's MLX library was praised for its performance on Apple Silicon, while Apple Intelligence features were criticized for being underwhelming. The rise of inference-scaling "reasoning" models, such as OpenAI's o1 models, was noted as a significant development. The environmental impact of LLMs was discussed, with improvements in efficiency contrasting against the massive infrastructure buildout by tech giants. The term "slop" gained traction to describe unwanted AI-generated content, and synthetic training data proved effective. The article concludes by highlighting the increasing complexity of using LLMs and the need for better criticism and education about their capabilities and limitations.
## Links

- [OpenAI DevDay 2024](https://openai.com/index/new-models-and-developer-products-announced-at-devday/) : OpenAI DevDay 2024 announcements, including new models and developer products.
- [Gemini 1.5 Pro](https://blog.google/technology/ai/google-gemini-ai/) : Google's Gemini 1.5 Pro model, featuring extended context lengths and multimodal capabilities.
- [ChatGPT Voice Mode](https://openai.com/index/chatgpt-can-now-see-hear-and-speak/) : ChatGPT's new voice mode, allowing users to interact with the model using audio input and output.
- [DeepSeek v3](https://api-docs.deepseek.com/news/news1120) : DeepSeek v3, a large open-source model with impressive performance and efficiency.

## Topics

![](topics/Model/GPT%204)

![](topics/Model/Gemini%201%205%20Pro)

![](topics/Model/Qwen2%205%20Coder%2032B)

![](topics/Model/Llama%203%203%2070B)

![](topics/Model/DeepSeek%20v3)

![](topics/Model/OpenAI%20o1)

![](topics/Concept/Inference%20scaling%20reasoning%20models)

![](topics/Concept/Slop)

![](topics/Concept/Synthetic%20Data%20Generation)

![](topics/Model/Claude%203%205%20Sonnet)
---
already_read: true
link: https://simonwillison.net/2024/Dec/31/llms-in-2024/
read_priority: 0
relevance: 3
source: Data Elixir
tags:
- Large_Language_Model
- AI_agent
type: Content
upload_date: '2025-01-08'
---

https://simonwillison.net/2024/Dec/31/llms-in-2024/
## Summary

In 2024, significant advancements were made in the field of Large Language Models (LLMs). Key developments include the breaking of the GPT-4 barrier by multiple organizations, with models like Google's Gemini 1.5 Pro and Anthropic's Claude 3 series surpassing GPT-4's capabilities. Notably, some GPT-4 class models can now run on personal laptops, highlighting improvements in model efficiency. Prices for LLM services crashed due to competition and increased efficiency, making them more accessible. Multimodal capabilities, including vision, audio, and video, became common, with live camera and voice modes emerging as groundbreaking features. Prompt-driven app generation became a commodity, enabling the creation of interactive applications through simple prompts. However, universal access to the best models was short-lived, and the concept of "agents" remained underdeveloped. Evaluations (evals) were recognized as crucial for building reliable LLM applications. Apple's MLX library was praised for its performance on Apple Silicon, while Apple's own "Apple Intelligence" features were deemed disappointing. Inference-scaling "reasoning" models, like OpenAI's o1 models, introduced a new approach to problem-solving by expending more compute time during inference. DeepSeek v3, a large openly licensed model, was trained for less than $6 million, showcasing significant training optimizations. While the environmental impact of individual prompts improved, the overall environmental impact of the infrastructure buildout remained a concern. The term "slop" gained traction to describe unwanted AI-generated content. Synthetic training data proved effective, and LLMs became harder to use due to their complexity and the need for specialized knowledge. The knowledge gap between LLM experts and the general public widened, and there was a call for better criticism and education about LLMs. The article concludes with a list of the author's blog posts on LLMs from 2024.
## Links

- [DeepSeek V3 Model](https://simonwillison.net/2024/Dec/25/deepseek-v3/) : DeepSeek V3 is a large 685B parameter model, one of the largest openly licensed models currently available, significantly bigger than the largest of Meta’s Llama series, Llama 3.1 405B.
- [Gemini 1.5 Flash 8B](https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/) : Gemini 1.5 Flash 8B is a model that is $0.0375/mTok—that’s 27x cheaper than GPT-3.5 Turbo last year.
- [OpenAI DevDay 2024](https://openai.com/index/new-models-and-developer-products-announced-at-devday/) : OpenAI DevDay 2024 announced new models and developer products, including GPT-4o, which is 12x cheaper than GPT-4.

## Topics

![[topics/Concept/Synthetic Data)]]

![[topics/Model/Gemini)]]

![[topics/Model/Claude 3 Series)]]

![[topics/Model/DeepSeek v3)]]

![[topics/Model/GPT 4)]]

![[topics/Concept/Slop)]]

![[topics/Model/Qwen2 5 Coder 32B)]]

![[topics/Model/Llama 4)]]

![[topics/Concept/Inference scaling reasoning models)]]

![[topics/Model/o1 Models)]]
---
already_read: true
link: https://simonwillison.net/2025/Dec/31/the-year-in-llms/
read_priority: 0
relevance: 4
source: Data Elixir
tags:
- Large_Language_Model
- AI_agent
type: Content
upload_date: '2026-01-24'
---

https://simonwillison.net/2025/Dec/31/the-year-in-llms/
## Summary

The article summarizes key trends and developments in the field of Large Language Models (LLMs) for the year 2025. Here are the main technical points and key takeaways:

1. **Reasoning Models**: The year saw a significant focus on reasoning models, with OpenAI leading the charge. These models use Reinforcement Learning from Verifiable Rewards (RLVR) to develop strategies that mimic human reasoning, making them highly effective for tasks like problem-solving and debugging code.

2. **Agents**: Despite initial skepticism, agents—LLMs that run tools in a loop to achieve goals—proved useful, especially in coding and search tasks. The "coding agents" pattern, exemplified by tools like Claude Code, became particularly impactful.

3. **Command-Line LLMs**: The use of LLMs on the command line gained traction, with tools like Claude Code demonstrating high revenue potential and developer adoption.

4. **YOLO Mode**: The "YOLO" (You Only Live Once) mode, which allows agents to operate without safety checks, became popular despite security risks. This mode highlights the trade-off between convenience and security.

5. **Subscription Models**: High-tier subscription plans, such as Claude Pro Max 20x and ChatGPT Pro, emerged, offering substantial discounts for heavy users of LLM services.

6. **Chinese Open Weight Models**: Chinese AI labs released top-ranked open weight models, challenging the dominance of Western AI labs. These models are often fully open-source and competitive with leading models from other regions.

7. **Long Tasks**: Advances in LLM capabilities enabled them to handle longer, more complex tasks, with some models achieving tasks that take humans multiple hours.

8. **Image Editing**: Prompt-driven image editing tools, like those integrated into ChatGPT, saw massive popularity, with features like "ghiblification" going viral.

9. **Academic Competitions**: LLMs achieved gold medal performance in prestigious academic competitions, demonstrating their advanced capabilities in math and programming.

10. **Loss of Leadership**: OpenAI faced competition from other AI labs, particularly Google Gemini, which made significant strides in model capabilities and hardware efficiency.

11. **Vibe Coding**: The term "vibe coding" was coined to describe a new, fun way of prototyping software using LLMs, emphasizing a hands-off approach to coding.

12. **Security Concerns**: The article highlights the security risks associated with AI-enabled browsers and the need for better safeguards against prompt injection attacks.

13. **Local vs. Cloud Models**: While local models improved significantly, cloud models continued to offer superior performance, particularly for complex tasks like coding agents.

14. **Environmental Impact**: Public opposition to data center construction grew due to concerns about energy consumption and environmental impact.

15. **Neologisms**: The article introduces several new terms, such as "the lethal trifecta" for prompt injection attacks that exfiltrate private data, and "vibe engineering" as a more professional approach to AI-assisted programming.

Overall, 2025 was a year of rapid advancements and growing pains in the LLM space, with significant improvements in model capabilities, new applications, and increasing awareness of the associated risks and challenges.
## Links

- [DeepSeek AI Models](https://huggingface.co/deepseek-ai) : DeepSeek AI models on Hugging Face, including DeepSeek 3 and DeepSeek R1, which are notable for their performance and impact on the AI and semiconductor markets.
- [Qwen Models](https://huggingface.co/Qwen) : Qwen models on Hugging Face, including Qwen-Image generation model and Qwen-Image-Edit, which are notable for their performance and impact on the AI and semiconductor markets.
- [Gemini Live API](https://ai.google.dev/gemini-api/docs/live-guide) : Gemini Live API documentation, providing insights into Google's advancements in AI, particularly in the context of reasoning models and their applications.

## Topics

![[topics/Concept/Reinforcement Learning from Verifiable Rewards RLVR]]

![[topics/Concept/Coding Agents]]

![[topics/Concept/Asynchronous Coding Agents]]

![[topics/Concept/YOLO Mode]]

![[topics/Concept/Normalization of Deviance]]

![[topics/Concept/Vibe Coding]]

![[topics/Concept/Conformance Suites]]

![[topics/Concept/Context Rot]]
---
already_read: false
link: https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/
read_priority: 4
relevance: 0
source: Data Points
tags:
- Large_Language_Model
- AI_agent
type: Content
upload_date: '2025-03-18'
---

https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/
## Summary

Gemini Robotics, a new model from Google DeepMind based on Gemini 2.0, is designed for robotics and introduces physical actions as a new output modality for direct robot control. It consists of two models: Gemini Robotics, an advanced vision-language-action (VLA) model, and Gemini Robotics-ER, which enhances spatial understanding for roboticists. These models enable robots to perform a wider range of real-world tasks and are being tested with partners like Apptronik. Key features include generality, interactivity, and dexterity, allowing robots to adapt to novel situations, understand and respond to natural language instructions, and perform complex tasks requiring fine motor skills. The models are designed to work with various robot types and include safety measures to ensure the physical safety of robots and humans. Google DeepMind is also releasing a new dataset to evaluate and improve semantic safety in embodied AI and robotics. The work is supported by a team of researchers and reviewed for responsible development and innovation.
## Links

- [Gemini Robotics Technical Report](https://arxiv.org/abs/2503.20020) : Technical report detailing the advancements and capabilities of Gemini Robotics.
- [ASIMOV Benchmark](https://asimov-benchmark.github.io/) : Dataset for evaluating and improving semantic safety in embodied AI and robotics.
- [ALOHA 2 Robotic Platform](https://aloha-2.github.io/) : Website for the ALOHA 2 bi-arm robotic platform used in training Gemini Robotics.

## Topics

![[topics/Model/Gemini]]

![[topics/Model/WeatherNext]]

![[topics/Model/AlphaFold]]

![[topics/Model/Gemini Robotics ER]]
---
already_read: false
link: https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/
read_priority: 4
relevance: 0
source: Data Points
tags:
- Large_Language_Model
- AI_agent
type: Content
upload_date: '2025-03-18'
---

https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/
## Summary

Gemini Robotics, a new AI model from Google DeepMind, is designed to bring AI into the physical world by enabling robots to perform real-world tasks. Built on Gemini 2.0, it introduces two models: Gemini Robotics, a vision-language-action model for direct robot control, and Gemini Robotics-ER, which enhances spatial understanding for roboticists. Key features include generality, interactivity, and dexterity, allowing robots to adapt to new situations, understand and respond to natural language commands, and perform complex tasks requiring fine motor skills. The models are designed to work with various robot types and are being tested with partners like Apptronik. Safety is a priority, with measures including low-level motor control, semantic understanding, and a new dataset for evaluating safety. The work is part of Google DeepMind's mission to build AI responsibly to benefit humanity.
## Links

- [ALOHA 2 Robotics Platform](https://aloha-2.github.io/) : The ALOHA 2 is a bi-arm robotic platform used in training Gemini Robotics, demonstrating its adaptability to different robot types.
- [Safe Robots Initiative](https://sites.google.com/corp/view/safe-robots) : This site discusses the safety measures and initiatives in robotics, relevant to the safety considerations mentioned in the article about Gemini Robotics.
- [Gemini Robotics Technical Report](https://arxiv.org/abs/2503.20020) : This technical report provides detailed insights into the development and capabilities of Gemini Robotics, including its vision-language-action model and embodied reasoning.

## Topics

![](topics/Model/Gemini%20Robotics)

![](topics/Model/Gemini%20Robotics%20ER)

![](topics/Concept/Embodied%20Reasoning)

![](topics/Concept/Vision%20Language%20Action%20VLA%20Model)
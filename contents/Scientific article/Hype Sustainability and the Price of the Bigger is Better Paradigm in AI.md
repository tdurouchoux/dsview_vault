---
already_read: true
link: https://arxiv.org/pdf/2409.14160
read_priority: 3
relevance: 0
source: Blef
tags:
- Large_Language_Model
type: Content
upload_date: '2025-01-14'
---

https://arxiv.org/pdf/2409.14160
## Summary

The paper critiques the "bigger-is-better" paradigm in AI, arguing that it is not sustainable and comes with undesirable consequences. The authors scrutinize the current scaling trends and trade-offs across multiple axes, refuting two common assumptions underlying the paradigm: that performance improvements are driven by increased scale, and that all interesting problems addressed by AI require large-scale models. The authors argue that this approach is not only fragile scientifically but also comes with undesirable consequences, including economic requirements and a disproportionate environmental footprint. The paper also discusses how the focus on scale implies focusing on certain problems at the expense of others, leaving aside important applications such as health, education, or the climate. Additionally, the concentration of power in the hands of a few actors is exacerbated, centralizing decision-making and threatening to disempower others in the context of shaping both AI research and its applications throughout society.

The paper is structured into several sections, including an introduction that outlines the main arguments, a section that examines what problems scale solves, a section on the consequences of the bigger-is-better paradigm, and a section on ways forward. The authors argue that the fixation on scale is misguided and that there are many interesting problems in AI that do not require scale. They also discuss the environmental impacts of large-scale AI, the invasive data gathering practices, and the concentration of power and innovation. The authors conclude by outlining how the research community can reclaim the scientific discourse in the AI field and move away from a singular focus on scale.
## Links


## Topics

![[topics/Concept/Bigger is Better Paradigm)]]

![[topics/Concept/Jevons Paradox)]]

![[topics/Concept/Model Evaluation)]]

![[topics/Concept/Data Contamination)]]

![[topics/Concept/Diminishing Returns of Scale)]]
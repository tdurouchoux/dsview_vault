---
already_read: false
link: https://hal.science/hal-03723551
read_priority: 1
relevance: 0
source: null
tags:
- Supervised_Learning
- Data_Analysis
type: Content
upload_date: '2023-05-04'
---

https://hal.science/hal-03723551
## Summary

The document presents a study comparing the performance of tree-based models and deep learning models on tabular data. Key points include:

1. **Benchmarking**: The study establishes a standard set of 48 datasets with clear tabular data characteristics and a benchmarking methodology that accounts for model fitting and hyperparameter tuning.

2. **Performance**: Results show that tree-based models like XGBoost and Random Forests remain state-of-the-art on medium-sized datasets (around 10,000 samples), even without considering their superior speed.

3. **Inductive Biases**: The study investigates the differing inductive biases of tree-based models and neural networks, identifying three main challenges for neural networks to address:
   - Robustness to uninformative features
   - Preservation of data orientation
   - Ability to learn irregular functions

4. **Research Stimulation**: The authors contribute a standard benchmark and raw data for baselines, including a comprehensive hyperparameter search to stimulate further research on tabular-specific neural network architectures.

The document is a communication presented at the 36th Conference on Neural Information Processing Systems (NeurIPS 2022) and is authored by Léo Grinsztajn, Edouard Oyallon, and Gaël Varoquaux.
## Links

- [ORCID - Edouard Oyallon](https://orcid.org/0000-0002-4826-7527) : ORCID profile of Edouard Oyallon, one of the authors of the paper.
- [ORCID - Gaël Varoquaux](https://orcid.org/0000-0003-1076-5122) : ORCID profile of Gaël Varoquaux, one of the authors of the paper.
- [arXiv - Preprint](https://arxiv.org/abs/2207.08815) : Preprint version of the paper available on arXiv.

## Topics

![](topics/Model/XGBoost)

![](topics/Model/Random%20Forests)

![](topics/Concept/Gradient%20Boosted%20Trees)
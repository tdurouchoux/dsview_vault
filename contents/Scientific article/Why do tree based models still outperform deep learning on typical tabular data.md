---
already_read: false
link: https://hal.science/hal-03723551
read_priority: 1
relevance: 0
source: null
tags:
- Supervised_Learning
- Model_evaluation
type: Content
upload_date: '2023-05-04'
---

https://hal.science/hal-03723551
## Summary

The document presents a study comparing the performance of tree-based models and deep learning models on tabular data. Key points include:

1. **Benchmarking**: The study establishes a standard set of 48 datasets and a benchmarking methodology to evaluate various models, including XGBoost, Random Forests, and several deep learning architectures.

2. **Performance**: Results indicate that tree-based models remain state-of-the-art on medium-sized datasets (around 10,000 samples), even without considering their superior speed.

3. **Inductive Biases**: The study investigates the differing inductive biases of tree-based models and neural networks, highlighting three main challenges for neural networks to address:
   - Robustness to uninformative features
   - Preservation of data orientation
   - Ability to learn irregular functions

4. **Research Stimulation**: The authors contribute a standard benchmark and raw data for baselines, encouraging further research on tabular-specific neural network architectures.

The document aims to stimulate research and provide a foundation for developing more effective deep learning models for tabular data.
## Links

- [Tabular_NeurIPS2022](https://hal.science/hal-03723551v3/file/Tabular_NeurIPS2022%20%2828%29.pdf) : PDF file of the research paper titled 'Why do tree-based models still outperform deep learning on typical tabular data?' presented at the 36th Conference on Neural Information Processing Systems (NeurIPS 2022).
- [arxiv](https://arxiv.org/abs/2207.08815) : arxiv page of the research paper titled 'Why do tree-based models still outperform deep learning on typical tabular data?' presented at the 36th Conference on Neural Information Processing Systems (NeurIPS 2022).

## Topics

![[topics/Model/XGBoost]]

![[topics/Model/Random Forest]]

![[topics/Concept/Tabular Data]]
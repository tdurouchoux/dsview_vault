---
already_read: true
link: https://deepmind.google/discover/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/
read_priority: 3
relevance: 0
source: Alpha Signal
tags:
- Large_Language_Model
type: Content
upload_date: '2024-12-28'
---

https://deepmind.google/discover/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/
## Summary

FACTS Grounding is a new benchmark introduced by Google DeepMind to evaluate the factual accuracy and grounding of large language models (LLMs). The benchmark addresses the issue of LLMs hallucinating false information, which can erode trust and limit their real-world applications. The FACTS Grounding dataset consists of 1,719 examples, divided into public and private sets, covering various domains and tasks. The dataset evaluates LLMs' ability to generate detailed, factually accurate responses grounded in provided documents.

The benchmark uses three leading LLMs (Gemini 1.5 Pro, GPT-4o, and Claude 3.5 Sonnet) as judges to evaluate responses automatically. The evaluation process involves two phases: checking eligibility and assessing factual accuracy. The final score is an average of all judge models' scores across all examples.

Google DeepMind encourages the AI community to engage with FACTS Grounding, evaluate their models, and submit them for evaluation. The benchmark and leaderboard will continue to evolve to keep pace with advancements in the field. The initiative is a collaboration between Google DeepMind and Google Research, with contributions from various researchers and teams.
## Links

- [FACTS Grounding Paper](https://goo.gle/FACTS_paper) : The paper detailing the methodology and findings of the FACTS Grounding benchmark.
- [FACTS Leaderboard](http://www.kaggle.com/facts-leaderboard) : The leaderboard on Kaggle showing the performance of various LLMs on the FACTS Grounding benchmark.
- [FACTS Grounding Dataset](http://www.kaggle.com/datasets/deepmind/facts-grounding-examples) : The dataset used for evaluating the factuality and grounding of LLMs, available on Kaggle.

## Topics

![](topics/Concept/FACTS%20Grounding)

![](topics/Dataset/FACTS%20Grounding%20Dataset)
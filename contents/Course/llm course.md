---
already_read: true
link: https://github.com/mlabonne/llm-course
read_priority: 0
relevance: 4
source: null
tags:
- Large_Language_Model
type: Content
upload_date: '2024-01-04'
---

https://github.com/mlabonne/llm-course
## Summary

The LLM course is structured into three main parts: LLM Fundamentals, LLM Scientist, and LLM Engineer.

**LLM Fundamentals** (optional) covers essential knowledge in mathematics, Python, neural networks, and NLP. It includes resources for linear algebra, calculus, probability, Python basics, data science libraries, neural network fundamentals, and NLP techniques like tokenization, word embeddings, and RNNs.

**LLM Scientist** focuses on building and optimizing LLMs. Key topics include LLM architecture, pre-training models, post-training datasets, supervised fine-tuning, preference alignment, evaluation, quantization, and new trends like model merging and multimodal models. It provides practical guides and references for each topic.

**LLM Engineer** covers deploying LLM-powered applications. Topics include running LLMs, building vector storage, retrieval augmented generation (RAG), advanced RAG techniques, agents, inference optimization, deploying LLMs, and securing LLMs. It offers practical tutorials and resources for each subject.

The course also includes a list of notebooks and tools for fine-tuning, quantization, and other tasks related to LLMs. Additionally, it mentions the LLM Engineer's Handbook, a detailed book covering end-to-end LLM application development.
## Links

- [LLM Course by Maxime Labonne](https://mlabonne.github.io/blog/) : The blog of Maxime Labonne, where he shares insights, tutorials, and updates related to Large Language Models (LLMs).
- [Hugging Face Lighteval](https://github.com/huggingface/lighteval) : A framework for evaluating LLMs using automated benchmarks and model-based evaluations.
- [Fine-tune Llama 3.1 with Unsloth](https://mlabonne.github.io/blog/posts/2024-07-29_Finetune_Llama31.html) : A tutorial on how to fine-tune a Llama 3.1 model using Unsloth.
- [4-bit Quantization with GPTQ](https://mlabonne.github.io/blog/4bit_quantization/) : A tutorial on how to quantize an LLM using the GPTQ algorithm with AutoGPTQ.
- [Merge LLMs with MergeKit](https://mlabonne.github.io/blog/posts/2024-01-08_Merge_LLMs_with_mergekit.html) : A tutorial on how to merge LLMs using MergeKit.

## Topics

![](topics/Concept/Tokenization)

![](topics/Concept/Attention%20Mechanisms)

![](topics/Concept/Language%20Model%20Sampling%20Techniques)

![](topics/Concept/Supervised%20Fine%20Tuning)

![](topics/Concept/Preference%20Alignment)

![](topics/Concept/Model%20Merging)

![](topics/Concept/AI%20Agents)

![](topics/Concept/Quantization)

![](topics/Concept/Retrieval%20Augmented%20Generation%20RAG)
---
already_read: false
link: https://lastexam.ai/
read_priority: 2
relevance: 0
source: Blef
tags:
- Large_Language_Model
- AI_agent
type: Content
upload_date: '2025-02-14'
---

https://lastexam.ai/
## Summary

The content introduces "Humanity's Last Exam" (HLE), a challenging, multi-modal benchmark designed to measure the capabilities of large language models (LLMs) at the frontier of human knowledge. The dataset consists of 2,500 questions across over a hundred subjects, contributed by nearly 1,000 experts from over 500 institutions worldwide.

Key points:

1. **Benchmark Purpose**: HLE aims to address the saturation of existing benchmarks, where LLMs achieve over 90% accuracy. HLE maintains low accuracy across several frontier models, demonstrating its effectiveness in measuring advanced, closed-ended, academic capabilities.

2. **Dataset**: The dataset is a global collaborative effort, with questions from experts, including professors, researchers, and graduate degree holders. Examples include questions from diverse fields such as Classics and Ecology.

3. **Quantitative Results**: The benchmark evaluates models on accuracy and calibration error. Current frontier models achieve low accuracy on HLE, highlighting the need for improvement in narrowing the gap between LLMs and expert-level academic capabilities.

4. **Future Model Performance**: While current LLMs perform poorly on HLE, the rapid pace of AI development suggests that models could exceed 50% accuracy on HLE by the end of 2025. High accuracy on HLE would demonstrate expert-level performance on closed-ended, verifiable questions and cutting-edge scientific knowledge.

5. **Impact**: HLE provides a clear measure of AI progress, enabling informed discussions about development trajectories, potential risks, and necessary governance measures. It serves as a common reference point for scientists and policymakers to assess AI capabilities.

6. **Related Articles**: The content includes references to articles from The New York Times and Reuters, discussing the significance and implications of HLE.

7. **Contact Information**: For inquiries or feedback, the contact email is provided as agibenchmark@safe.ai.

The content emphasizes the importance of HLE in tracking AI advancements and its potential impact on future AI development and governance.
## Links

- [Humanity's Last Exam GitHub Repository](https://github.com/centerforaisafety/hle) : The GitHub repository for Humanity's Last Exam, a multi-modal benchmark at the frontier of human knowledge.
- [Humanity's Last Exam Dataset on Hugging Face](https://huggingface.co/datasets/cais/hle) : The Humanity's Last Exam dataset available on Hugging Face, consisting of 2,500 challenging questions across over a hundred subjects.
- [Humanity's Last Exam Results](https://scale.com/blog/humanitys-last-exam-results) : A blog post detailing the results of Humanity's Last Exam, showcasing the performance of various frontier models.
- [The New York Times Article on Humanity's Last Exam](https://www.nytimes.com/2025/01/23/technology/ai-test-humanitys-last-exam.html) : An article discussing the significance and implications of Humanity's Last Exam as a benchmark for AI capabilities.
- [Reuters Article on Humanity's Last Exam](https://www.reuters.com/technology/artificial-intelligence/ai-experts-ready-humanitys-last-exam-stump-powerful-tech-2024-09-16/) : A Reuters article covering the introduction of Humanity's Last Exam and its purpose in challenging advanced AI models.

## Topics

![](topics/Dataset/Humanity%20s%20Last%20Exam%20HLE)
---
already_read: true
link: https://huggingface.co/docs/hub/en/ollama
read_priority: 5
relevance: 0
source: Alpha Signal
tags:
- Large_Language_Model
type: Content
upload_date: '2024-12-28'
---

https://huggingface.co/docs/hub/en/ollama
## Summary

The document provides instructions on using Ollama with GGUF models on the Hugging Face Hub. Key points include:

1. **General Usage**: Ollama can run any GGUF model from the Hugging Face Hub using a simple command, with 45K public GGUF checkpoints available.

2. **Custom Quantization**: Users can select different quantization schemes by specifying the quantization tag in the command.

3. **Custom Chat Template and Parameters**: Users can customize chat templates, system prompts, and sampling parameters by creating specific files (template, system, params) in the repository.

4. **Private GGUFs**: To run private GGUF models, users need to add their Ollama SSH key to their Hugging Face account settings.

5. **References**: Links to Ollama's documentation and Hugging Face's GGUF documentation are provided for further details.

The document is structured into sections: Custom Quantization, Custom Chat Template and Parameters, Run Private GGUFs from the Hugging Face Hub, and References.
## Links

- [Ollama Documentation](https://github.com/ollama/ollama/blob/main/docs/README.md) : The official documentation for Ollama, providing detailed information on how to use the application with GGUF models.
- [GGUF Usage with Ollama](https://huggingface.co/docs/hub/en/gguf) : Detailed guide on using GGUF models with Ollama on the Hugging Face Hub.

## Topics

![](topics/Concept/GGUF)

![](topics/Platform/Hugging%20Face)

![](topics/Tool/Ollama)